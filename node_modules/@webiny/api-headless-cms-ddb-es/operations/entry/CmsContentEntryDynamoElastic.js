"use strict";

var _interopRequireDefault = require("@babel/runtime/helpers/interopRequireDefault");

Object.defineProperty(exports, "__esModule", {
  value: true
});
exports.default = exports.TYPE_ENTRY_PUBLISHED = exports.TYPE_ENTRY_LATEST = exports.TYPE_ENTRY = void 0;

var _defineProperty2 = _interopRequireDefault(require("@babel/runtime/helpers/defineProperty"));

var _error = _interopRequireDefault(require("@webiny/error"));

var _lodash = _interopRequireDefault(require("lodash.clonedeep"));

var _lodash2 = _interopRequireDefault(require("lodash.omit"));

var _dataLoaders = require("./dataLoaders");

var _types = require("@webiny/api-headless-cms/types");

var _configurations = _interopRequireDefault(require("../../configurations"));

var _utils = require("@webiny/api-headless-cms/utils");

var _helpers = require("../../helpers");

var _utils2 = require("../../utils");

var _limit = require("@webiny/api-elasticsearch/limit");

var _cursors = require("@webiny/api-elasticsearch/cursors");

var _compression = require("@webiny/api-elasticsearch/compression");

function ownKeys(object, enumerableOnly) { var keys = Object.keys(object); if (Object.getOwnPropertySymbols) { var symbols = Object.getOwnPropertySymbols(object); if (enumerableOnly) { symbols = symbols.filter(function (sym) { return Object.getOwnPropertyDescriptor(object, sym).enumerable; }); } keys.push.apply(keys, symbols); } return keys; }

function _objectSpread(target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i] != null ? arguments[i] : {}; if (i % 2) { ownKeys(Object(source), true).forEach(function (key) { (0, _defineProperty2.default)(target, key, source[key]); }); } else if (Object.getOwnPropertyDescriptors) { Object.defineProperties(target, Object.getOwnPropertyDescriptors(source)); } else { ownKeys(Object(source)).forEach(function (key) { Object.defineProperty(target, key, Object.getOwnPropertyDescriptor(source, key)); }); } } return target; }

const TYPE_ENTRY = "cms.entry";
exports.TYPE_ENTRY = TYPE_ENTRY;
const TYPE_ENTRY_LATEST = TYPE_ENTRY + ".l";
exports.TYPE_ENTRY_LATEST = TYPE_ENTRY_LATEST;
const TYPE_ENTRY_PUBLISHED = TYPE_ENTRY + ".p";
exports.TYPE_ENTRY_PUBLISHED = TYPE_ENTRY_PUBLISHED;

const getEntryData = (context, entry) => {
  return _objectSpread(_objectSpread({}, (0, _lodash2.default)(entry, ["PK", "SK", "published", "latest"])), {}, {
    TYPE: TYPE_ENTRY,
    __type: TYPE_ENTRY
  });
};

const getESLatestEntryData = async (context, entry) => {
  return (0, _compression.compress)(context, _objectSpread(_objectSpread({}, getEntryData(context, entry)), {}, {
    latest: true,
    TYPE: TYPE_ENTRY_LATEST,
    __type: TYPE_ENTRY_LATEST
  }));
};

const getESPublishedEntryData = async (context, entry) => {
  return (0, _compression.compress)(context, _objectSpread(_objectSpread({}, getEntryData(context, entry)), {}, {
    published: true,
    TYPE: TYPE_ENTRY_PUBLISHED,
    __type: TYPE_ENTRY_PUBLISHED
  }));
};

/**
 * This implementation is not a general driver to fetch from DDB/Elastic.
 * Use some other implementation for general-use purpose.
 */
class CmsContentEntryDynamoElastic {
  get esClient() {
    if (this._esClient) {
      return this._esClient;
    }

    const ctx = this.context;

    if (!ctx.elasticsearch) {
      throw new _error.default("Missing Elasticsearch client on the context");
    }

    this._esClient = ctx.elasticsearch;
    return this._esClient;
  }

  get partitionKey() {
    return `${(0, _utils2.createBasePartitionKey)(this.context)}#CME`;
  }

  constructor({
    context
  }) {
    (0, _defineProperty2.default)(this, "context", void 0);
    (0, _defineProperty2.default)(this, "_dataLoaders", void 0);
    (0, _defineProperty2.default)(this, "_esClient", void 0);
    this.context = context;
    this._dataLoaders = new _dataLoaders.DataLoadersHandler(context, this);
  }

  async create(model, args) {
    const {
      db
    } = this.context;
    const {
      entry,
      storageEntry
    } = args; // const storageEntry = await entryToStorageTransform(this.context, model, data);

    const esEntry = (0, _helpers.prepareEntryToIndex)({
      context: this.context,
      model,
      storageEntry: (0, _lodash.default)(storageEntry)
    });

    const {
      index: esIndex
    } = _configurations.default.es(this.context, model);

    const esLatestData = await getESLatestEntryData(this.context, esEntry);
    const batch = db.batch()
    /**
     * Create main entry item
     */
    .create(_objectSpread(_objectSpread({}, _configurations.default.db()), {}, {
      data: _objectSpread({
        PK: this.getPartitionKey(entry.id),
        SK: this.getSortKeyRevision(entry.version),
        TYPE: TYPE_ENTRY
      }, storageEntry)
    }))
    /**
     * Create "latest" entry item
     */
    .create(_objectSpread(_objectSpread({}, _configurations.default.db()), {}, {
      data: _objectSpread({
        PK: this.getPartitionKey(entry.id),
        SK: this.getSortKeyLatest(),
        TYPE: TYPE_ENTRY_LATEST
      }, storageEntry)
    })).create(_objectSpread(_objectSpread({}, _configurations.default.esDb()), {}, {
      data: {
        PK: this.getPartitionKey(entry.id),
        SK: this.getSortKeyLatest(),
        index: esIndex,
        data: esLatestData
      }
    }));

    try {
      await batch.execute();
    } catch (ex) {
      throw new _error.default(ex.message || "Could not insert data into the DynamoDB", ex.code || "CREATE_ENTRY_ERROR", {
        error: ex,
        entry,
        storageEntry,
        esEntry
      });
    }

    return storageEntry;
  }

  async createRevisionFrom(model, args) {
    const {
      db
    } = this.context;
    const {
      originalEntry,
      entry,
      storageEntry
    } = args;
    const esEntry = (0, _helpers.prepareEntryToIndex)({
      context: this.context,
      model,
      storageEntry: (0, _lodash.default)(storageEntry)
    });

    const {
      index: esIndex
    } = _configurations.default.es(this.context, model);

    const primaryKey = this.getPartitionKey(storageEntry.id);
    const batch = db.batch();
    const esLatestData = await getESLatestEntryData(this.context, esEntry);
    batch
    /**
     * Create main entry item
     */
    .create(_objectSpread(_objectSpread({}, _configurations.default.db()), {}, {
      data: _objectSpread({
        PK: primaryKey,
        SK: this.getSortKeyRevision(storageEntry.version),
        TYPE: TYPE_ENTRY
      }, getEntryData(this.context, storageEntry))
    }))
    /**
     * Update "latest" entry item
     */
    .update(_objectSpread(_objectSpread({}, _configurations.default.db()), {}, {
      query: {
        PK: primaryKey,
        SK: this.getSortKeyLatest()
      },
      data: _objectSpread({
        PK: primaryKey,
        SK: this.getSortKeyLatest(),
        TYPE: TYPE_ENTRY_LATEST
      }, getEntryData(this.context, storageEntry))
    }))
    /**
     * Update the "latest" entry item in the Elasticsearch
     */
    .update(_objectSpread(_objectSpread({}, _configurations.default.esDb()), {}, {
      query: {
        PK: primaryKey,
        SK: this.getSortKeyLatest()
      },
      data: {
        PK: primaryKey,
        SK: this.getSortKeyLatest(),
        index: esIndex,
        data: esLatestData
      }
    }));

    try {
      await batch.execute();
    } catch (ex) {
      throw new _error.default(ex.message || "Could not create revision from given entry.", ex.code || "CREATE_REVISION_ERROR", {
        error: ex,
        originalEntry,
        entry,
        storageEntry,
        esEntry
      });
    }
    /**
     * There are no modifications on the entry created so just return the data.
     */


    return storageEntry;
  }

  async delete(model, args) {
    const {
      db
    } = this.context;
    const {
      entry
    } = args;
    const primaryKey = this.getPartitionKey(entry.id);
    const [dbItems] = await db.read(_objectSpread(_objectSpread({}, _configurations.default.db()), {}, {
      query: {
        PK: primaryKey,
        SK: {
          $gte: " "
        }
      }
    }));
    /**
     * Load ES entries to delete
     */

    const [esDbItems] = await db.read(_objectSpread(_objectSpread({}, _configurations.default.esDb()), {}, {
      query: {
        PK: primaryKey,
        SK: {
          $gte: " "
        }
      }
    }));
    /**
     * Delete all items from DB and ES DB
     */

    await Promise.all([(0, _utils2.paginateBatch)(dbItems, 25, async items => {
      await db.batch().delete(...items.map(item => _objectSpread(_objectSpread({}, _configurations.default.db()), {}, {
        query: {
          PK: item.PK,
          SK: item.SK
        }
      }))).execute();
    }), (0, _utils2.paginateBatch)(esDbItems, 25, async items => {
      await db.batch().delete(...items.map(item => _objectSpread(_objectSpread({}, _configurations.default.esDb()), {}, {
        query: {
          PK: item.PK,
          SK: item.SK
        }
      }))).execute();
    })]);
  }

  async deleteRevision(model, args) {
    const {
      db
    } = this.context;
    const {
      entryToDelete,
      entryToSetAsLatest,
      storageEntryToSetAsLatest
    } = args;
    const primaryKey = this.getPartitionKey(entryToDelete.id);

    const esConfig = _configurations.default.es(this.context, model);
    /**
     * We need published entry to delete it if necessary.
     */


    const publishedStorageEntry = await this.getPublishedRevisionByEntryId(model, entryToDelete.id);
    /**
     * We need to delete all existing records of the given entry revision.
     */

    const batch = db.batch();
    /**
     * Delete records of given entry revision.
     */

    batch.delete(_objectSpread(_objectSpread({}, _configurations.default.db()), {}, {
      query: {
        PK: primaryKey,
        SK: this.getSortKeyRevision(entryToDelete.id)
      }
    })).delete(_objectSpread(_objectSpread({}, _configurations.default.esDb()), {}, {
      query: {
        PK: primaryKey,
        SK: this.getSortKeyRevision(entryToDelete.id)
      }
    }));
    /**
     * If revision we are deleting is the published one as well, we need to delete those records as well.
     */

    if (publishedStorageEntry && entryToDelete.id === publishedStorageEntry.id) {
      batch.delete(_objectSpread(_objectSpread({}, _configurations.default.db()), {}, {
        query: {
          PK: primaryKey,
          SK: this.getSortKeyPublished()
        }
      })).delete(_objectSpread(_objectSpread({}, _configurations.default.esDb()), {}, {
        query: {
          PK: primaryKey,
          SK: this.getSortKeyPublished()
        }
      }));
    }

    if (entryToSetAsLatest) {
      const esEntry = (0, _helpers.prepareEntryToIndex)({
        context: this.context,
        model,
        storageEntry: (0, _lodash.default)(storageEntryToSetAsLatest)
      });
      const esLatestData = await getESLatestEntryData(this.context, esEntry);
      /**
       * In the end we need to set the new latest entry
       */

      batch.update(_objectSpread(_objectSpread({}, _configurations.default.db()), {}, {
        query: {
          PK: primaryKey,
          SK: this.getSortKeyLatest()
        },
        data: _objectSpread(_objectSpread({}, storageEntryToSetAsLatest), {}, {
          TYPE: TYPE_ENTRY_LATEST
        })
      })).update(_objectSpread(_objectSpread({}, _configurations.default.esDb()), {}, {
        query: {
          PK: primaryKey,
          SK: this.getSortKeyLatest()
        },
        data: {
          PK: primaryKey,
          SK: this.getSortKeyLatest(),
          index: esConfig.index,
          data: esLatestData
        }
      }));
    }

    try {
      await batch.execute();
    } catch (ex) {
      throw new _error.default(ex.message, ex.code, {
        error: ex,
        entryToDelete,
        entryToSetAsLatest,
        storageEntryToSetAsLatest
      });
    }
  }

  async get(model, args) {
    const {
      items
    } = await this.list(model, _objectSpread(_objectSpread({}, args || {}), {}, {
      limit: 1
    }));

    if (items.length === 0) {
      return null;
    }

    return items.shift();
  }
  /**
   * Implemented search via the Elasticsearch.
   */


  async list(model, args) {
    const limit = (0, _limit.createLimit)(args.limit, 50);
    const body = (0, _helpers.createElasticsearchQueryBody)({
      model,
      args: _objectSpread(_objectSpread({}, args || {}), {}, {
        limit
      }),
      context: this.context,
      parentPath: "values"
    });
    let response;

    const esConfig = _configurations.default.es(this.context, model);

    try {
      response = await this.esClient.search(_objectSpread(_objectSpread({}, esConfig), {}, {
        body
      }));
    } catch (ex) {
      throw new _error.default(ex.message, ex.code || "ELASTICSEARCH_ERROR", {
        error: ex,
        esConfig,
        body
      });
    }

    const {
      hits,
      total
    } = response.body.hits;
    const items = (0, _helpers.extractEntriesFromIndex)({
      context: this.context,
      model,
      entries: hits.map(item => item._source)
    });
    const hasMoreItems = items.length > limit;

    if (hasMoreItems) {
      /**
       * Remove the last item from results, we don't want to include it.
       */
      items.pop();
    }
    /**
     * Cursor is the `sort` value of the last item in the array.
     * https://www.elastic.co/guide/en/elasticsearch/reference/current/paginate-search-results.html#search-after
     */


    const cursor = items.length > 0 ? (0, _cursors.encodeCursor)(hits[items.length - 1].sort) : null;
    return {
      hasMoreItems,
      totalCount: total.value,
      cursor,
      items
    };
  }

  async update(model, args) {
    const {
      originalEntry,
      entry,
      storageEntry // latestEntry

    } = args;
    const {
      db
    } = this.context;
    const primaryKey = this.getPartitionKey(originalEntry.id);
    /**
     * We need the latest entry to check if it needs to be updated.
     */

    const latestStorageEntry = await this.getLatestRevisionByEntryId(model, originalEntry.id);
    const batch = db.batch();
    batch.update(_objectSpread(_objectSpread({}, _configurations.default.db()), {}, {
      query: {
        PK: primaryKey,
        SK: this.getSortKeyRevision(originalEntry.version)
      },
      data: _objectSpread(_objectSpread({}, storageEntry), {}, {
        SK: this.getSortKeyRevision(originalEntry.version)
      })
    }));
    /**
     * If the latest entry is the one being updated, we need to create a new latest entry records.
     */

    if (latestStorageEntry.id === originalEntry.id) {
      /**
       * First we update the regular DynamoDB table
       */
      batch.update(_objectSpread(_objectSpread({}, _configurations.default.db()), {}, {
        query: {
          PK: primaryKey,
          SK: this.getSortKeyLatest()
        },
        data: _objectSpread(_objectSpread({}, storageEntry), {}, {
          TYPE: TYPE_ENTRY_LATEST,
          PK: primaryKey,
          SK: this.getSortKeyLatest()
        })
      }));
      /**
       * And then update the Elasticsearch table to propagate changes to the Elasticsearch
       */

      const esEntry = (0, _helpers.prepareEntryToIndex)({
        context: this.context,
        model,
        storageEntry: (0, _lodash.default)(storageEntry)
      });

      const esDoc = _objectSpread(_objectSpread({}, esEntry), {}, {
        savedOn: storageEntry.savedOn
      });

      const {
        index: esIndex
      } = _configurations.default.es(this.context, model);

      const esLatestData = await getESLatestEntryData(this.context, esDoc);
      batch.update(_objectSpread(_objectSpread({}, _configurations.default.esDb()), {}, {
        query: {
          PK: primaryKey,
          SK: this.getSortKeyLatest()
        },
        data: {
          PK: primaryKey,
          SK: this.getSortKeyLatest(),
          index: esIndex,
          data: esLatestData
        }
      }));
    }

    try {
      await batch.execute();

      this._dataLoaders.clearAllEntryRevisions(model);

      return storageEntry;
    } catch (ex) {
      throw new _error.default(ex.message || "Could not update entry.", ex.code || "UPDATE_ERROR", {
        error: ex,
        originalEntry,
        entry,
        storageEntry,
        latestStorageEntry
      });
    }
  }

  async publish(model, args) {
    const {
      db
    } = this.context;
    const {
      entry,
      storageEntry // latestEntry,
      // publishedEntry

    } = args;
    /**
     * We need currently published entry to check if need to remove it.
     */

    const publishedStorageEntry = await this.getPublishedRevisionByEntryId(model, entry.id);
    const primaryKey = this.getPartitionKey(entry.id);
    const readBatch = db.batch().read(_objectSpread(_objectSpread({}, _configurations.default.esDb()), {}, {
      query: {
        PK: primaryKey,
        SK: this.getSortKeyLatest()
      }
    })).read(_objectSpread(_objectSpread({}, _configurations.default.esDb()), {}, {
      query: {
        PK: primaryKey,
        SK: this.getSortKeyPublished()
      }
    }));
    let latestESEntryData;
    let publishedESEntryData;

    try {
      [[[latestESEntryData]], [[publishedESEntryData]]] = await readBatch.execute();
    } catch (ex) {
      throw new _error.default(ex.message || "Could not read Elasticsearch latest or published data.", ex.code || "PUBLISH_BATCH_READ", {
        latest: {
          PK: primaryKey,
          SK: this.getSortKeyLatest()
        },
        published: {
          PK: primaryKey,
          SK: this.getSortKeyPublished()
        }
      });
    }

    const batch = db.batch();
    batch.update(_objectSpread(_objectSpread({}, _configurations.default.db()), {}, {
      query: {
        PK: primaryKey,
        SK: this.getSortKeyRevision(entry.version)
      },
      data: _objectSpread(_objectSpread({}, storageEntry), {}, {
        SK: this.getSortKeyRevision(entry.version)
      })
    }));

    const es = _configurations.default.es(this.context, model);

    if (publishedStorageEntry) {
      /**
       * If there is a `published` entry already, we need to set it to `unpublished`. We need to
       * execute two updates: update the previously published entry's status and the published entry record.
       * DynamoDB does not support `batchUpdate` - so here we load the previously published
       * entry's data to update its status within a batch operation. If, hopefully,
       * they introduce a true update batch operation, remove this `read` call.
       */
      const [[previouslyPublishedStorageEntry]] = await db.read(_objectSpread(_objectSpread({}, _configurations.default.db()), {}, {
        query: {
          PK: primaryKey,
          SK: this.getSortKeyRevision(publishedStorageEntry.version)
        }
      }));
      previouslyPublishedStorageEntry.status = _types.CONTENT_ENTRY_STATUS.UNPUBLISHED;
      batch.update(_objectSpread(_objectSpread({}, _configurations.default.db()), {}, {
        query: {
          PK: primaryKey,
          SK: this.getSortKeyRevision(publishedStorageEntry.version)
        },
        data: _objectSpread(_objectSpread({}, previouslyPublishedStorageEntry), {}, {
          SK: this.getSortKeyRevision(publishedStorageEntry.version),
          savedOn: entry.savedOn
        })
      })).update(_objectSpread(_objectSpread({}, _configurations.default.db()), {}, {
        query: {
          PK: primaryKey,
          SK: this.getSortKeyPublished()
        },
        data: _objectSpread(_objectSpread({}, getEntryData(this.context, storageEntry)), {}, {
          PK: primaryKey,
          SK: this.getSortKeyPublished()
        })
      }));
    } else {
      batch.create(_objectSpread(_objectSpread({}, _configurations.default.db()), {}, {
        data: _objectSpread(_objectSpread({}, getEntryData(this.context, storageEntry)), {}, {
          PK: primaryKey,
          SK: this.getSortKeyPublished(),
          TYPE: TYPE_ENTRY_PUBLISHED
        })
      }));
    }
    /**
     * We need the latest entry to check if it neds to be updated as well in the Elasticsearch.
     */


    const latestStorageEntry = await this.getLatestRevisionByEntryId(model, entry.id);
    /**
     * If we are publishing the latest revision, let's also update the latest revision's status in ES.
     */

    if (latestStorageEntry && latestStorageEntry.id === entry.id) {
      /**
       * Need to decompress the data from Elasticsearch DynamoDB table.
       */
      const latestEsEntryDataDecompressed = await (0, _compression.decompress)(this.context, latestESEntryData.data);
      batch.update(_objectSpread(_objectSpread({}, _configurations.default.esDb()), {}, {
        query: {
          PK: primaryKey,
          SK: this.getSortKeyLatest()
        },
        data: _objectSpread(_objectSpread({}, latestESEntryData), {}, {
          SK: this.getSortKeyLatest(),
          data: _objectSpread(_objectSpread({}, latestEsEntryDataDecompressed), {}, {
            status: _types.CONTENT_ENTRY_STATUS.PUBLISHED,
            locked: true,
            savedOn: entry.savedOn,
            publishedOn: entry.publishedOn
          })
        })
      }));
    }

    const preparedEntryData = (0, _helpers.prepareEntryToIndex)({
      context: this.context,
      model,
      storageEntry: (0, _lodash.default)(storageEntry)
    });
    /**
     * Update the published revision entry in ES.
     */

    const esLatestData = await getESPublishedEntryData(this.context, preparedEntryData);
    const esData = {
      PK: primaryKey,
      SK: this.getSortKeyPublished(),
      index: es.index,
      data: esLatestData
    };

    if (publishedESEntryData) {
      batch.update(_objectSpread(_objectSpread({}, _configurations.default.esDb()), {}, {
        query: {
          PK: primaryKey,
          SK: this.getSortKeyPublished()
        },
        data: esData
      }));
    } else {
      batch.create(_objectSpread(_objectSpread({}, _configurations.default.esDb()), {}, {
        data: esData
      }));
    }
    /**
     * Finally, execute batch
     */


    try {
      await batch.execute();

      this._dataLoaders.clearAllEntryRevisions(model, entry);

      return entry;
    } catch (ex) {
      throw new _error.default(ex.message || "Could not execute the publishing batch.", ex.code || "PUBLISH_ERROR", {
        entry,
        esData,
        latestStorageEntry,
        publishedStorageEntry
      });
    }
  }

  async unpublish(model, args) {
    const {
      db
    } = this.context;
    const {
      entry,
      storageEntry
    } = args;
    /**
     * We need the latest entry to check if it needs to be updated.
     */

    const latestStorageEntry = await this.getLatestRevisionByEntryId(model, entry.id);
    const primaryKey = this.getPartitionKey(entry.id);
    const batch = db.batch().delete(_objectSpread(_objectSpread({}, _configurations.default.db()), {}, {
      query: {
        PK: primaryKey,
        SK: this.getSortKeyPublished()
      }
    })).delete(_objectSpread(_objectSpread({}, _configurations.default.esDb()), {}, {
      query: {
        PK: primaryKey,
        SK: this.getSortKeyPublished()
      }
    })).update(_objectSpread(_objectSpread({}, _configurations.default.db()), {}, {
      query: {
        PK: primaryKey,
        SK: this.getSortKeyRevision(entry.version)
      },
      data: _objectSpread(_objectSpread({}, storageEntry), {}, {
        SK: this.getSortKeyRevision(entry.version)
      })
    }));
    /**
     * If we are unpublishing the latest revision, let's also update the latest revision entry's status in ES.
     */

    if (latestStorageEntry.id === entry.id) {
      const es = _configurations.default.es(this.context, model);

      const preparedEntryData = (0, _helpers.prepareEntryToIndex)({
        context: this.context,
        model,
        storageEntry: (0, _lodash.default)(storageEntry)
      });
      const esLatestData = await getESLatestEntryData(this.context, preparedEntryData);
      batch.update(_objectSpread(_objectSpread({}, _configurations.default.esDb()), {}, {
        query: {
          PK: primaryKey,
          SK: this.getSortKeyLatest()
        },
        data: {
          PK: primaryKey,
          SK: this.getSortKeyLatest(),
          index: es.index,
          data: esLatestData
        }
      }));
    }

    try {
      await batch.execute();
      return entry;
    } catch (ex) {
      throw new _error.default(ex.message || "Could not execute unpublish batch.", ex.code || "UNPUBLISH_ERROR", {
        entry,
        latestStorageEntry
      });
    }
  }

  async requestChanges(model, args) {
    const {
      db
    } = this.context;
    const {
      entry,
      storageEntry,
      originalEntry
    } = args;
    /**
     * We need the latest entry to check if it needs to be updated.
     */

    const latestStorageEntry = await this.getLatestRevisionByEntryId(model, entry.id);
    const primaryKey = this.getPartitionKey(entry.id);
    const batch = db.batch().update(_objectSpread(_objectSpread({}, _configurations.default.db()), {}, {
      query: {
        PK: primaryKey,
        SK: this.getSortKeyRevision(entry.version)
      },
      data: _objectSpread(_objectSpread({}, storageEntry), {}, {
        SK: this.getSortKeyRevision(entry.version)
      })
    }));
    /**
     * If we updated the latest version, then make sure the changes are propagated to ES too.
     */

    if (latestStorageEntry.id === entry.id) {
      const es = _configurations.default.es(this.context, model);

      const preparedEntryData = (0, _helpers.prepareEntryToIndex)({
        context: this.context,
        model,
        storageEntry: (0, _lodash.default)(storageEntry)
      });
      const esLatestData = await getESLatestEntryData(this.context, preparedEntryData);
      batch.update(_objectSpread(_objectSpread({}, _configurations.default.esDb()), {}, {
        query: {
          PK: primaryKey,
          SK: this.getSortKeyLatest()
        },
        data: {
          PK: primaryKey,
          SK: this.getSortKeyLatest(),
          index: es.index,
          data: esLatestData
        }
      }));
    }

    try {
      await batch.execute();
    } catch (ex) {
      throw new _error.default(ex.message || "Could not execute the request changes batch.", ex.code || "REQUEST_CHANGES_ERROR", {
        entry,
        originalEntry
      });
    }

    return entry;
  }

  async requestReview(model, args) {
    const {
      db
    } = this.context;
    const {
      entry,
      storageEntry,
      originalEntry
    } = args;
    /**
     * We need the latest entry to check if it needs to be updated.
     */

    const latestStorageEntry = await this.getLatestRevisionByEntryId(model, entry.id);
    const primaryKey = this.getPartitionKey(entry.id);
    const batch = db.batch().update(_objectSpread(_objectSpread({}, _configurations.default.db()), {}, {
      query: {
        PK: primaryKey,
        SK: this.getSortKeyRevision(entry.version)
      },
      data: _objectSpread(_objectSpread({}, storageEntry), {}, {
        SK: this.getSortKeyRevision(entry.version)
      })
    }));
    /**
     * If we updated the latest version, then make sure the changes are propagated to ES too.
     */

    if (latestStorageEntry.id === entry.id) {
      const es = _configurations.default.es(this.context, model);

      const preparedEntryData = (0, _helpers.prepareEntryToIndex)({
        context: this.context,
        model,
        storageEntry: (0, _lodash.default)(storageEntry)
      });
      const esLatestData = await getESLatestEntryData(this.context, preparedEntryData);
      batch.update(_objectSpread(_objectSpread({}, _configurations.default.esDb()), {}, {
        query: {
          PK: primaryKey,
          SK: this.getSortKeyLatest()
        },
        data: {
          PK: primaryKey,
          SK: this.getSortKeyLatest(),
          index: es.index,
          data: esLatestData
        }
      }));
    }

    try {
      await batch.execute();
      return entry;
    } catch (ex) {
      throw new _error.default(ex.message || "Could not execute request review batch.", ex.code || "REQUEST_REVIEW_ERROR", {
        entry,
        latestStorageEntry,
        originalEntry
      });
    }
  }

  async getAllRevisionsByIds(model, ids) {
    if (ids.length === 0) {
      return [];
    }

    try {
      return await this._dataLoaders.getAllEntryRevisions(model, ids);
    } catch (ex) {
      throw new _error.default(ex.message || "Could not read multiple entries.", ex.code || "GET_ALL_REVISIONS_BY_IDS_ERROR", {
        ids
      });
    }
  }

  async getByIds(model, ids) {
    if (ids.length === 0) {
      return [];
    }

    try {
      return await this._dataLoaders.getRevisionById(model, ids);
    } catch (ex) {
      throw new _error.default(ex.message || "Could not read multiple entries.", ex.code || "GET_BY_IDS_ERROR", {
        ids
      });
    }
  }

  async getPublishedByIds(model, ids) {
    if (ids.length === 0) {
      return [];
    }

    try {
      return await this._dataLoaders.getPublishedRevisionByEntryId(model, ids);
    } catch (ex) {
      throw new _error.default(ex.message || "Could not read multiple entries.", ex.code || "GET_BY_IDS_ERROR", {
        ids
      });
    }
  }

  async getLatestByIds(model, ids) {
    if (ids.length === 0) {
      return [];
    }

    try {
      return await this._dataLoaders.getLatestRevisionByEntryId(model, ids);
    } catch (ex) {
      throw new _error.default(ex.message || "Could not read multiple entries.", ex.code || "GET_BY_IDS_ERROR", {
        ids
      });
    }
  }

  async getRevisions(model, id) {
    try {
      return await this._dataLoaders.getAllEntryRevisions(model, [id]);
    } catch (ex) {
      throw new _error.default(ex.message || "Could not read multiple entries.", ex.code || "GET_ALL_REVISIONS_BY_IDS_ERROR", {
        id
      });
    }
  }

  async getRevisionById(model, id) {
    return this.getSingleDynamoDbItem({
      PK: this.getPartitionKey(id),
      SK: this.getSortKeyRevision(id)
    });
  }

  async getPublishedRevisionByEntryId(model, entryId) {
    return this.getSingleDynamoDbItem({
      PK: this.getPartitionKey(entryId),
      SK: this.getSortKeyPublished()
    });
  }

  async getLatestRevisionByEntryId(model, entryId) {
    return this.getSingleDynamoDbItem({
      PK: this.getPartitionKey(entryId),
      SK: this.getSortKeyLatest()
    });
  }

  async getPreviousRevision(model, entryId, version) {
    const entry = await this.getSingleDynamoDbItem({
      PK: this.getPartitionKey(entryId),
      SK: {
        $lt: this.getSortKeyRevision(version)
      }
    }, {
      SK: -1
    });
    /**
     * When there are no lower versions from the given one, it seems that random one is taken.
     * So just make sure that fetched entry version is not greater or equal to requested one.
     */

    if (!entry || entry.version >= version) {
      return null;
    }
    /**
     * We need this due to possibly getting latest or published if given revision does not exist
     */


    if (entry.TYPE !== TYPE_ENTRY) {
      return null;
    }

    return entry;
  }

  async getSingleDynamoDbItem(query, sort) {
    const {
      db
    } = this.context;
    let entry;

    try {
      const [entries] = await db.read(_objectSpread(_objectSpread({}, _configurations.default.db()), {}, {
        query,
        sort,
        limit: 1
      }));

      if (entries.length === 0) {
        return null;
      }

      entry = entries.shift();
    } catch (ex) {
      throw new _error.default(ex.message || "Could not read from the DynamoDB.", ex.code || "DDB_READ_ERROR", {
        query,
        sort
      });
    }

    return entry;
  }

  getPartitionKey(id) {
    /**
     * If ID includes # it means it is composed of ID and VERSION.
     * We need ID only so extract it.
     */
    if (id.includes("#")) {
      id = id.split("#").shift();
    }

    return `${this.partitionKey}#${id}`;
  }
  /**
   * Gets a sort key in form of REV#version from:
   *   id#0003
   *   0003
   *   3
   */


  getSortKeyRevision(version) {
    if (typeof version === "string" && version.includes("#") === true) {
      version = version.split("#").pop();
    }

    return `REV#${(0, _utils.zeroPad)(version)}`;
  }

  getSortKeyLatest() {
    return "L";
  }

  getSortKeyPublished() {
    return "P";
  }

}

exports.default = CmsContentEntryDynamoElastic;
//# sourceMappingURL=CmsContentEntryDynamoElastic.js.map